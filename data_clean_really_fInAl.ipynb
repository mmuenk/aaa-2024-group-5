{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ebb91d-56bb-4405-9203-2ec04df2e1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Timedelta\n",
    "import numpy as np\n",
    "import re\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a514bc-45a6-42a2-a2f3-455c91824dea",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        Load the data in chunks\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "064d2567-3cb1-4cdf-ae20-61722218b97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('taxi_main copy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dfd9fc-a27b-4891-98c6-7c19eb084ab9",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 40px; font-weight: bold; color: #8EB944\">\n",
    "        Formatting\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711df1b0-75de-4609-b32d-ffc3b0aee5df",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        1. Change the variable names\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfa0ce0-d180-4d56-a50d-dd35d0c8d241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "df.rename(columns = dict(zip(['Taxi ID', 'Trip Start Timestamp', 'Trip End Timestamp', 'Trip Seconds',\n",
    "       'Trip Miles', 'Pickup Census Tract', 'Dropoff Census Tract',\n",
    "       'Pickup Community Area', 'Dropoff Community Area', 'Fare', \n",
    "       'Extras','Pickup Centroid Location',\n",
    "       'Dropoff Centroid  Location'], ['taxi_id', 'trip_start', 'trip_end', 'trip_seconds',\n",
    "       'trip_miles', 'pickup_census', 'dropoff_census',\n",
    "       'pickup_comm_area', 'dropoff_comm_area', 'fare', \n",
    "       'extras',  'pickup_location',\n",
    "       'dropoff_location'])), inplace = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ce560-73be-41b3-b6d5-314887720521",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        2. Map the Taxi Id's to numeric values\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94bf03c-509a-40fa-9d68-c3cd563513a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi_id_map = dict(zip(df['taxi_id'].unique(),range(len(df['taxi_id'].unique() ))))\n",
    "df['taxi_id'] = df['taxi_id'].apply(lambda x: taxi_id_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4963110-5ef2-473b-a9a8-55b549ab5752",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        3. Reduce the precision of the GPS data for consistency\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b116f1a-0b3a-481e-b84c-154a6b88ac41",
   "metadata": {},
   "source": [
    "We reduce the GPS coordinates to 10 digits for now, as this is the minimum precision all points have. We can reuse the function later to reduce the precision to 6 or 7 digits for the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2692c7-c418-4888-acad-9d139ac9723b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use pythons regular expressions to find all the seperating '.' in a Point object. Then truncate both coordinates after 10 digits.\n",
    "\n",
    "def format_point(point):\n",
    "    if isinstance(point, str):  \n",
    "        # Extract the numbers\n",
    "        matches = re.findall(r'(-?\\d+\\.\\d+)', point)\n",
    "        \n",
    "        # If there exactly two coordinates with a '.' , we can truncate the coordinates to 10 digits.\n",
    "        if matches and len(matches) == 2:\n",
    "            lon, lat = matches\n",
    "            # Truncate to 10 decimal places\n",
    "            lon = lon[:lon.index('.') + 11]\n",
    "            lat = lat[:lat.index('.') + 11]\n",
    "            return f\"POINT ({lon} {lat})\"\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06de945-a715-4e00-a688-ed22e371a071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'pickup_location'] = df['pickup_location'].apply(format_point)\n",
    "df.loc[:, 'dropoff_location'] = df['dropoff_location'].apply(format_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1787bb5-f9a9-4992-bc82-b512e6799170",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4. Change the datatype of the timestamps\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b66ad7-e03d-4ac6-aa9d-854fb61fcd63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert columns to datetime\n",
    "df['trip_start'] = pd.to_datetime(df['trip_start'])\n",
    "df['trip_end'] = pd.to_datetime(df['trip_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70813bb4-2961-48fa-849d-a9daa472d5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09525408-5274-4f95-be74-93938028658a",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        5. Change the datatype of the Census Tracts\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d3cb75-3fef-4ef7-afa4-5f8c093ab79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the census tracts and fill the NA's with zeros\n",
    "df['pickup_census'] = pd.to_numeric(df['pickup_census'], errors='coerce').fillna(0).astype('Int64')\n",
    "df['dropoff_census'] = pd.to_numeric(df['dropoff_census'], errors='coerce').fillna(0).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28621d4-8266-427c-93ab-b10621cc2c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e4dfa0a-fa26-405c-8c73-bbb1355b15a4",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        6. Split timestamps into 'Day' and  'Hour' variables\n",
    "        </span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a95d069-84f8-4eea-92f4-209883fb1469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['start_day'] = df['trip_start'].dt.date\n",
    "df['end_day'] = df['trip_end'].dt.date\n",
    "\n",
    "df['start_time'] = df['trip_start'].dt.time\n",
    "df['end_time'] = df['trip_end'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db6a1c-1c64-4ab9-b2b4-8fbae8a32a64",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        7. Calculate estimate for the trip duration with the timestamps\n",
    "        </span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19cee2d4-12dd-4070-b486-871cd68094fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the trip duration with the time stamps, because some trip seconds data are erroneous\n",
    "df['trip_duration'] = df['trip_end'] - df['trip_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce45e3c-b681-46f9-a352-17fde425069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6b485f-4dc7-44f6-91e5-2ea59115fca9",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        8. Convert the locations to shapely Point objects\n",
    "        </span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f789f60f-d183-4e28-98cf-c37c5a3d0bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_to_point(point_str):\n",
    "    if pd.isna(point_str):\n",
    "        return None\n",
    "    return wkt.loads(point_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ff88d5-96f7-46a6-ade9-0a508bed0925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['dropoff_location'] = df['dropoff_location'].apply(string_to_point)\n",
    "df['pickup_location'] = df['pickup_location'].apply(string_to_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0199f-f53f-4995-909d-1294faad5ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52fa152c-305a-4682-9719-e539bc948231",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        9. Drop unnecessary variables\n",
    "        </span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92c1f2f-2f63-4026-93b9-9cc024ed5b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['Trip ID','Trip Total','Tips','Payment Type','Pickup Centroid Latitude','Pickup Centroid Longitude', 'Tolls', 'Company',\n",
    "         'Dropoff Centroid Latitude','Dropoff Centroid Longitude'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9adb6-c700-4dc3-83d6-a9853aa8951d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c868169-68f6-42e2-b46d-7c1bd662bfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "773fe230-5c36-4a30-a5d4-62fdd1e63f6e",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 40px; font-weight: bold; color: #8EB944\">\n",
    "        Dropping outliers by looking at scenarios\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3011775-0ef3-41d7-ba67-37b63adde843",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        1. Drop rides that ended before they started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12cd20d2-fc53-4c9f-8573-e7ed724d4ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter the indexes of rides that ended before they started and subsequently drop them\n",
    "inval_time = df[df['trip_end'] < df['trip_start']].index\n",
    "df.drop(inval_time, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c182c918-6399-42ed-b80a-19a9868b42d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inval_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caa78b-9da7-43c5-bf21-b6f686b4b6b8",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        2. Drop  rides with inconsistent timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434ca1d5-1a5e-41df-b4ea-8958d335c1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter the indexes of rides that started and ended in the same 15 minute interval but where the ride  took longer than 15 minutes\n",
    "time_errors = df[(df['trip_end'] == df['trip_start']) & \n",
    "(df['trip_seconds']>900)].index\n",
    "df.drop(time_errors, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873ad2de-56a6-4e00-bc17-5b0a386e1583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f3154-e8b2-4029-bff6-35b35bccc406",
   "metadata": {},
   "source": [
    "After handling these scenarios, the timestamps are no longer needed and can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82e640-3908-4ae3-bc9d-2cdd429db44e",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "         Drop the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3efd016d-f581-42ba-ae90-86f56af24194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['trip_start', 'trip_end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3bf6c-1694-47c3-a31e-29d8a5ddfa84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36755cd1-2516-484e-8af6-fcd8bc61929d",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        3. Drop rides without valid fares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a744b4c1-31e8-4d97-b2f7-3022ca3658c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter the indexes of rides with a fare of less than 3.25$ (minimum fare) dollars and subsequently drop them\n",
    "inval_fare = df[df['fare']<3.25].index\n",
    "df.drop(inval_fare, inplace = True)\n",
    "\n",
    "# filter the indexes of rides with a fare of exactly 3.25$ but more than a mile traveled (each additional mile costs 2,25$)\n",
    "inval_fare2 = df[(df['fare']==3.25) & (df['trip_miles'] >1)].index\n",
    "df.drop(inval_fare2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e57aea39-eac4-4174-a974-7a301bdc26bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122 96\n"
     ]
    }
   ],
   "source": [
    "print(len(inval_fare),len(inval_fare2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aeaf3b-34db-4e02-969f-2f3778c88022",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4. Drop extremely long rides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad349bf6-5056-493e-9ec4-9f2659b61d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use pandas timedelta for filtering rides  that lasted  more than 8 hours and drop them, as these are likely outliers.\n",
    "long_rides =  df[df['trip_duration']>Timedelta('0 days 04:00:00')].index\n",
    "df.drop(long_rides, inplace = True)\n",
    "\n",
    "# lets also  drop  the rides that were longer than 8 hours according  to the trip seconds.\n",
    "longer_rides =  df[df['trip_seconds'] >= 14400].index\n",
    "df.drop(longer_rides, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f38b6f37-27a3-4f68-93ed-30d7a30b8ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509 14\n"
     ]
    }
   ],
   "source": [
    "print(len(long_rides),len(longer_rides))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c609d78-2d3f-4eb6-be2d-a9764867fc3c",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        5. Drop missing fares, trip seconds and trip miles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e0bc5-c229-46f9-abcb-fe3ccf968f33",
   "metadata": {},
   "source": [
    "As there are only 1500 missing values combined for the 3 variables: 'Fare', 'Trip Seconds', 'Trip Miles', we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b1e5620-e5f8-4658-82a8-84920a390246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_miles = df[df['trip_miles'].isna()].index\n",
    "df.drop(missing_miles, inplace = True)\n",
    "\n",
    "\n",
    "missing_seconds = df[df['trip_seconds'].isna()].index\n",
    "df.drop(missing_seconds, inplace = True)\n",
    "\n",
    "\n",
    "missing_fares = df[df['fare'].isna()].index\n",
    "df.drop(missing_fares, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aae640f1-e153-4111-942c-433e5f0caed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 29 44\n"
     ]
    }
   ],
   "source": [
    "print(len(missing_seconds), len(missing_miles), len(missing_fares))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8632776-324e-4f51-8832-81e0ee85f805",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        6. Drop rides where the taxi was stationary\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80a592-52ee-4d3f-8321-12ea513a2ca7",
   "metadata": {},
   "source": [
    "We assume that in order for a ride to be valid, the taxi has to move some time. Thus, the trip seconds or trip miles shouldnt be 0 or the dropoff location is different to the pickup location. A fare of more than 0 dollars alone doesnt constitute a valid ride, because there may have been problems with the taxometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77fef023-1caa-427a-8faa-52caee8cf80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter rides that have the  same start and endtime, 0 trip seconds and 0 trip miles and the same pickup and dropoff location\n",
    "\n",
    "invalid_rides = df[(df['trip_seconds']==0) & (df['trip_duration'] == Timedelta('0 days 00:00:00'))\n",
    "& (df['pickup_location'] == df['dropoff_location'])\n",
    "& (df['trip_miles'] == 0)].index\n",
    "df.drop(invalid_rides, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1efd42b-a1f6-4816-92f0-57e051d4e3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8635"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invalid_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc104c5c-ec74-464b-9913-09a591831d32",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        7. Drop rides with illogical prices\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc652f-9597-4c49-ac23-df15f15fdfeb",
   "metadata": {},
   "source": [
    "Official prices for taxis in chicago in 2020 can be found here: https://www.chicago.gov/content/dam/city/depts/bacp/publicvehicleinfo/Chicabs/chicagotaxiplacard20200629.pdf.\n",
    "The prices for 2019 cannot be found on the offical pages anymore, but we only use them as a loose orientation.\n",
    "Since we only have the total fare and not all the components contributing to the fare, it is quite difficult to catch all outliers.\n",
    "Due to this, we look for outliers by using the percentiles of the 'Fare' variable in combination with other variables.\n",
    "A fare in the 99.9 percentile (92 Dollars or more) should correspond to a very far or long ride or someone had to pay 50 Dollars for throwing up in the cab.\n",
    "We are not interested in the latter and thus filter out all the rides that paid more than 92 Dollars but were not among either the 99,5% longest rides in terms of mileage or trip duration. These percentiles may seeem arbitray but make sense, when considering the cost from the link provided above. The minimum fare is 3,25USD, each mile is 2,25USD and each minute is 0,34USD. The 99.5th percentile for the trip duration is 75 minutes, the 99.5th percentile for the trip duration is 25 miles. This yields an expected price of 3,25+(0,34*75)+(25*2,25)=85USD. This still leaves a margin of 7 dollars for the airport tax and other fees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1304f79c-36f8-43dc-95d6-51d9fe9eb2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A price in the 99.9 percentile should correspond to a very far or long ride         \n",
    "drop_fares = df[(df['fare']>np.percentile(df['fare'],99.9)) & \n",
    "                       ((df['trip_miles'] < df['trip_miles'].quantile(0.995)) &\n",
    "                        (df['trip_duration'] < df['trip_duration'].quantile(0.995)))].index\n",
    "# drop the outliers\n",
    "df.drop(drop_fares, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4cd778-1d18-4ebb-b85e-e0d3794d7f17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drop_fares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d20de1a-2fb7-4317-88bb-e320499e5ae6",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        8. Drop rides that took 0 seconds\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2e6eaaf-dcb2-4c75-ae25-a470ea148b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_trips = df[(df['trip_seconds']==0) & (df['trip_duration']==Timedelta('0 days 00:00:00'))].index\n",
    "df.drop(zero_trips, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb00fab-32fc-4b35-a48f-a035ee8128fe",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        9. Drop rides that exceeded the extras limit\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dcd707-f1f2-4935-a529-7eb1138dd867",
   "metadata": {},
   "source": [
    "When considering the prices for extras from the website cited above, it is highly unlikely to observe a rider where the customer paid more than 60 Dollars for extras alone. Thus, we flag these rides as outliers and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e6a55b9-4861-4732-a36b-9e0d199b4288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "idx2 = df[df['extras']>=60].index\n",
    "\n",
    "df.drop(idx2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea928295-c7d9-4afc-ac19-68b14207edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1228c-2c32-4fb1-a360-98a349f6201e",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        10. Drop rides that have 0 trip miles, 0 trip duration and the same start and end location\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52ab89-455d-4f21-9614-0340740941df",
   "metadata": {},
   "source": [
    "These rides could be the result of errors in the taxometer. And even if they are not, since they have 0 trip miles and the same start and end location, we argue that they were not actual rides. A valid fare does not constitute a valid ride. The taxi should bring a person from A to B, else we should not consider the ride valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d0f701f-fb05-422d-ba77-5ac4cb3013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_rides = df[(df['trip_miles']==0) & (df['trip_duration']==Timedelta('0 days 00:00:00'))&\n",
    "(df['pickup_location']==df['dropoff_location'])].index\n",
    "\n",
    "df.drop(short_rides, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a816503-098f-4c37-90f5-60911ff6f142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ffc43-555b-409c-a62e-153b98716a7c",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 40px; font-weight: bold; color: #8EB944\">\n",
    "        Dropping outliers with quantiles\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221eb7b-d89d-46c5-a407-8e72fc3bbe5f",
   "metadata": {},
   "source": [
    "We assume that the scenarios in the previous section did not catch all outliers, because there are probably 100 more scenarios. Since we cannot check each ride, we now remove rides by looking at the percentile values of the 2 KPI's 'Trip Miles' and 'Fare'. We do not remove outliers based on the variable 'Trip Seconds' or 'Trip Duration', because we already filtered out all the rides that were longer than 8 hours. We decide to drop all rides with 'Fares' or 'Trip Miles' more than 5 standard deviations away from the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2cbfe99-2aa0-48d8-aeda-746367455c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25000      6.000000\n",
       "0.50000      8.000000\n",
       "0.75000     13.500000\n",
       "0.90000     36.000000\n",
       "0.99000     53.000000\n",
       "0.99500     63.750000\n",
       "0.99900     87.500000\n",
       "0.99950    100.000000\n",
       "0.99990    148.750000\n",
       "0.99995    194.984875\n",
       "0.99999    867.360954\n",
       "Name: fare, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare'].quantile([0.25,0.5,0.75,0.9,0.99,0.995,0.999,0.9995,0.9999, 0.99995, 0.99999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19edb4-18e6-4918-9c5d-d1f25c2440cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Question:</b> All of the prices seem feasible.... Maybe don't do this? Maybe look at the quantiles in the table and choose one?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "057fa0d7-08b2-4a03-aaa5-da491eee280a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_fares = df[df['fare']>df['fare'].mean() + 5 *df['fare'].std()].index\n",
    "df.drop(high_fares, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6511e401-5c42-45ee-838d-d04af923dd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_fares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9489be8-1f1d-4e7a-b258-9f00dc574a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25000      0.670000\n",
       "0.50000      1.280000\n",
       "0.75000      3.100000\n",
       "0.90000     12.750000\n",
       "0.99000     20.300000\n",
       "0.99500     24.830000\n",
       "0.99900     33.400000\n",
       "0.99950     36.920390\n",
       "0.99990     44.858234\n",
       "0.99995     47.526858\n",
       "0.99999    116.288624\n",
       "Name: trip_miles, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trip_miles'].quantile([0.25,0.5,0.75,0.9,0.99,0.995,0.999,0.9995,0.9999, 0.99995, 0.99999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45b1a5ed-a0a7-42dc-8976-418f819505c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_mileage = df[df['trip_miles']>df['trip_miles'].mean() + 5 *df['trip_miles'].std()].index\n",
    "df.drop(high_mileage, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28f79d36-be4e-4fed-8dc7-30f0b074ec88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_mileage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83f6c3-6948-4383-8b42-96d8e9749c42",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 40px; font-weight: bold; color: #8EB944\">\n",
    "        Spatial data cleaning\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a21158-1a3d-448a-b3bf-dc364062ab69",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        1.  Drop rides with no spatial information\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1cd445e-11f4-453a-bde4-19107cac2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df[(df['pickup_census']==0) & (df['pickup_comm_area'].isna()) &\n",
    "     (df['pickup_location'].isna()) ].index\n",
    "df.drop(idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e11b4a2-0630-4ea8-81d4-52740c81b5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42444"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043aa581-03fe-42d8-87aa-e83a4373c625",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        2.  Drop rides that started outside the city\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0d9ce-060e-4c2a-b7bc-4f0b58d5d3f7",
   "metadata": {},
   "source": [
    "There are some rides that have no pickup community area and no pickup location but a pickup census tract. When filtering these rides and looking up the location of these census tracts on https://www.chicagocityscape.com/maps/index.php#/?search_term=17031803005&places_type=censustract, we can observe that these rides started outside of the city. Hence, we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6482263-fe73-4e46-935e-c19e0b153920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_chic = df[(df.pickup_location.isna()) & (df.pickup_comm_area.isna())].index\n",
    "df.drop(out_of_chic, inplace=True)\n",
    "len(out_of_chic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea96dd-f049-452f-a910-d24d6eb07185",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        3.  Reassign some rides to census tracts entirely within Chicago\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21980001-4851-4653-ba83-7ab58400bbf6",
   "metadata": {},
   "source": [
    "Some rides started within Chicago, but their census tracts are only partially inside the city. Take census  tract 17031770700 which is barely touching the Census tract 17031980000 (chicago O'hare airport). The locations for this rides are the centroids for the part of the census tract that is within chicago. As we only have the areas of the census tracts inside the city and this problem only applies to this one census tract, we decide to manually reassign these rides to the census tract of the airport. We do this instead of completely droping these rides, because these are quite a few rides and they clearly belong to the census tract with the chicago O'hare airport.\n",
    "https://www.chicagocityscape.com/maps/index.php#/?search_term=17031770700&places_type=censustract&place=communityarea-roseland.\n",
    "Therefore, we will map the rides from the census tract 17031770700 onto the census tract 17031980000, because this is the only one that overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df1917de-71e5-48af-85f4-0d263539e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### let us retrieve the location data for the census tract 17031980000\n",
    "\n",
    "new_cens = 17031980000\n",
    "new_loc = df[df.pickup_census==17031980000].iloc[0].pickup_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0338973f-46d5-46dc-b17e-e62dd85618c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the location of census tract 17031770700\n",
    "old_loc = df[df.pickup_census==17031770700].iloc[0].pickup_location\n",
    "\n",
    "# reassign the rides\n",
    "df.loc[df.pickup_census == 17031770700, 'pickup_census'] = new_cens\n",
    "df.loc[df.pickup_census == old_loc, 'pickup_location'] = new_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90a9a5-1a6f-4358-af49-78c3407296dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e6e6bf9-03f5-422d-9295-ee7eb1f7deea",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.  Assign census tracts via the community areas for the censored rides\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443dfc3-8033-4589-9c8c-6d89d6695185",
   "metadata": {},
   "source": [
    "Problem Description: There are roughly 4 Million rides that have no census tract but only a community area. Refering to the description of the dataset, this is the case, because the location of these rides has been censored for whatever reason. This is a problem, because the remaining 12 million rides have location on a census tract resolution. Thus, the majority of the data have more precise location information than the 4 million rides that have the centroids of the community areas as the locations. This is particularly problematic for the clustering, as the 4 million  rides basically have been aggregated. That leaves us with 2 options: 1. We could assign the rides with census tract level resolution to the community areas. This would of course mean that we lose data accuracy. 2. We could reallocate the 4 million rides to get census tract level resolution for out entire sample. Of course this will assign rides to census tracts that might not actually had any rides in it.\n",
    "We still choose to the latter option, because this should yield a more accurate distribution of rides than the one provided in the dataset.\n",
    "\n",
    "We randomly assign the rides with no census tract to one census tract that is within the community area where the ride started or ended. The random allocation ensures that we do not introduce any unnecessary bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31863644-1d0a-4f84-83ec-9df5e5f20acf",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.1 Load the data for the census tracts and community areas from the city of chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43f0ec1d-2d23-4c3e-be17-7195628f8081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "census = gpd.read_file('Boundaries.geojson')\n",
    "comm_area = gpd.read_file('comm_area.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ce202-ec2d-4fa4-9183-97d6c8eabaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4e9bcf-53f7-497c-bd44-b28107f8d5c7",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.2  Create a dictionary that maps the community areas to all the census tracts thats in it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b9b45-472d-45d2-9644-2ca0e1f56504",
   "metadata": {},
   "source": [
    "Note: There are two scenarios: 1. The census tracts is entirely inside a community area. In that case, we simply map the census tract to the community area. 2. Some census tracts are in several community areas. In that case, we calculate the area of overlap and assign the census tract to the community area with the largest overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c467b54-b1bd-4a0f-9916-663cc9c45e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dict that contains each comm area as the key\n",
    "commarea_to_census = {int(comm):[] for comm in census.commarea_n.unique()}\n",
    "\n",
    "for k in range(len(census)):\n",
    "    \n",
    "    # Create a list to store the corresponding comm areas for each census tract\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(comm_area)):  \n",
    "    \n",
    "        # Check whether the comm area overlaps with the census tract and save the area\n",
    "        if census.geometry[k].overlaps(comm_area.geometry[i]) == True:\n",
    "    \n",
    "            intersection = census.geometry[k].intersection(comm_area.geometry[i])\n",
    "            intersection_area = intersection.area/census.geometry[k].area\n",
    "            \n",
    "            \n",
    "            results.append([int(comm_area.iloc[i][4]),intersection_area]) \n",
    "        \n",
    "        # Check whether the census tract is within the comm area\n",
    "        elif census.geometry[k].within(comm_area.geometry[i]):\n",
    "            results.append([int(comm_area.iloc[i][4]),1])\n",
    "      \n",
    "    # Sort the list to get the comm area with the biggest overlap\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Append the census tract to the corresponding comm area\n",
    "    commarea_to_census[results[0][0]].append(int(census.geoid10[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339fab8-fbcf-4d20-a043-e47383795dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b832cb-d139-4138-a39a-189a6d814ce5",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.3  Map the pickup census tracts to the pickup locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64ed20-bb6e-4bc2-8f1d-2590044c61ce",
   "metadata": {},
   "source": [
    "There is a 1:1 relationship between the unique values of the pickup census tracts and pickup centroid locations, as the locations are the centroids of the census tracts. However, there are 800 census tracts in the city of chicago, but just 537 in our dataset, thus, we must calculate the centroids of the other census tracts with geopandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b638223-6283-4d94-a6d2-5a200d28d9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dict to map each census tract to its location\n",
    "# no 0 in the keys\n",
    "census_map_pickup = {int(x): [] for x in census.geoid10}\n",
    "\n",
    "# Populate the dict witht the corresponding centroid locations of the census tracts\n",
    "for key in census_map_pickup:\n",
    "    \n",
    "    if key in df['pickup_census'].unique():\n",
    "    \n",
    "        # Search the DataFrame for the Census Tract and get the corresponding location\n",
    "        index = df[df['pickup_census']==key].index[0]\n",
    "        location = df.loc[index,'pickup_location']\n",
    "    \n",
    "        census_map_pickup[key] = location\n",
    "    else:\n",
    "        loc = census.geoid10[census.geoid10 == str(key)].index\n",
    "        \n",
    "        # Supress the warning about the accuracy of centroid\n",
    "        with warnings.catch_warnings():           \n",
    "            warnings.filterwarnings('ignore', message=\"Geometry is in a geographic CRS.*centroid\", category=UserWarning)\n",
    "    \n",
    "        \n",
    "            centroid = census.loc[loc,'geometry'].centroid.iloc[0]\n",
    "        \n",
    "            \n",
    "             # Convert coordinates to strings and truncate after 10 decimal places\n",
    "            centroid_x = float(str(centroid.x)[:str(centroid.x).find('.') + 11])\n",
    "            centroid_y = float(str(centroid.y)[:str(centroid.y).find('.') + 11])\n",
    "\n",
    "            # Create a new Point with the truncated coordinates\n",
    "            trunc_centroid = Point(centroid_x, centroid_y)\n",
    "\n",
    "            # populate the dictionary with the calculated centroid\n",
    "            census_map_pickup[key] = trunc_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2bc9f-c8fb-439b-963a-1de24031ad9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0082785c-87b8-4d5b-a24e-e6da4a79c6ca",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.4  Map the dropoff census tracts to the dropoff locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b1efb8-2f5e-4b1d-b275-ab57f85fffff",
   "metadata": {},
   "source": [
    "Since there are slightly more unique dropoff census tracts in the taxi trip datasets than there are unique census tracts, we create a seperate dictionary, using the same methodolgy, to create consistency of locations. We do this , because we donot exactly know which CRS was used to calculate the centroids in the taxi trip dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0e48c36-9aeb-4d41-8a12-90be62733029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict to map each census tract to its location\n",
    "# no 0 in the keys\n",
    "census_map_dropoff = {int(x): [] for x in census.geoid10}\n",
    "\n",
    "# Populate the dict witht the corresponding centroid locations of the census tracts\n",
    "for key in census_map_dropoff:\n",
    "    \n",
    "    if key in df['dropoff_census'].unique():\n",
    "    \n",
    "        # Search the DataFrame for the Census Tract and get the corresponding location\n",
    "        index = df[df['dropoff_census']==key].index[0]\n",
    "        location = df.loc[index,'dropoff_location']\n",
    "    \n",
    "        census_map_dropoff[key] = location\n",
    "    else:\n",
    "        loc = census.geoid10[census.geoid10 == str(key)].index\n",
    "        \n",
    "        # Supress the warning about the accuracy of centroid\n",
    "        with warnings.catch_warnings():           \n",
    "            warnings.filterwarnings('ignore', message=\"Geometry is in a geographic CRS.*centroid\", category=UserWarning)\n",
    "    \n",
    "        \n",
    "            centroid = census.loc[loc,'geometry'].centroid.iloc[0]\n",
    "            \n",
    "            # Convert coordinates to strings and truncate after 10 decimal places\n",
    "            centroid_x = float(str(centroid.x)[:str(centroid.x).find('.') + 11])\n",
    "            centroid_y = float(str(centroid.y)[:str(centroid.y).find('.') + 11])\n",
    "\n",
    "            # Create a new Point with the truncated coordinates\n",
    "            trunc_centroid = Point(centroid_x, centroid_y)\n",
    "\n",
    "        \n",
    "            census_map_dropoff[key] = trunc_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ace2f-6dbe-4d24-b858-1af2112b2699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb06310b-7743-48cb-82ae-5c9d80a330f9",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.5  Assign the trips with no pickup census tract to a random census tract in the community area and change the location accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4a34c0c-fa55-4aa4-9ef8-2e69eaa78f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_pickup_location(comm_area:int):\n",
    "    # randomly assign a census tract for the community area from the commarea_to_census  dictionary\n",
    "    # get the number of census tracts in the community area\n",
    "    n_cens = len(commarea_to_census[comm_area])\n",
    "    \n",
    "    # sample a random number between 0 and the number of census tracts in the community area minus one\n",
    "    rand_cens = np.random.randint(n_cens)\n",
    "    # get the corresponding census tract\n",
    "    new_cens = commarea_to_census[comm_area][rand_cens]\n",
    "\n",
    "    # get the corresponding location \n",
    "    new_loc = census_map_pickup[new_cens]\n",
    "\n",
    "    return new_cens, new_loc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f52dfce7-15ee-4aab-94cf-ae7c532621f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_reassign_pickup(row):\n",
    "    new_cens, new_loc = reassign_pickup_location(row['pickup_comm_area'])\n",
    "    row['pickup_census'] = new_cens\n",
    "    row['pickup_location'] = new_loc\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "056aafaf-6d4e-431f-931b-28cb11ee7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_update = df[df.pickup_census==0].index\n",
    "df.loc[indexes_to_update] = df.loc[indexes_to_update].apply(apply_reassign_pickup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4a28e-7669-467a-8c2e-1064691460d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c7f3e05-f510-45c3-b305-68b2cdf8cb2a",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        4.6  Assign the trips with no dropoff census tract to a random census tract in the community area and change the location accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24f01c94-4006-482e-ba80-fb39ba2e1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_dropoff_location(comm_area:int):\n",
    "    # randomly assign a census tract for the community area from the commarea_to_census  dictionary\n",
    "    # get the number of census tracts in the community area\n",
    "    n_cens = len(commarea_to_census[comm_area])\n",
    "    \n",
    "    # sample a random number between 0 and the number of census tracts in the community area minus one\n",
    "    rand_cens = np.random.randint(n_cens)\n",
    "    # get the corresponding census tract\n",
    "    new_cens = commarea_to_census[comm_area][rand_cens]\n",
    "\n",
    "    # get the corresponding location \n",
    "    new_loc = census_map_dropoff[new_cens]\n",
    "\n",
    "    return new_cens, new_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27146c59-81b4-48ea-aca5-3f55be5b4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_reassign_dropoff(row):\n",
    "    if  pd.notna(row['dropoff_comm_area']):\n",
    "        \n",
    "        new_cens, new_loc = reassign_dropoff_location(row['dropoff_comm_area'])\n",
    "        row['dropoff_census'] = new_cens\n",
    "        row['dropoff_location'] = new_loc\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd938252-5820-4004-be77-89c4e894b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only apply the function the rides where we have no dropoff census tract\n",
    "indexes_to_update = df[df.dropoff_census==0].index\n",
    "df.loc[indexes_to_update] = df.loc[indexes_to_update].apply(apply_reassign_dropoff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cec56-b75a-41b3-a2df-6527f37217de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8c7e959-4367-420f-ae85-5eb27ddb5865",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        5.  Check whether any rides started outside of the city\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1052af-8fc5-4246-a03e-f233c7ccb0bd",
   "metadata": {},
   "source": [
    "Let us check for each unique pickup location whether it started within a community area or a census tract of the city of chicago.\n",
    "We do not check this for the dropoff locations, as we did not drop rides that had no dropoff community area/ dropoff location/dropoff census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4038b453-6326-4724-ad7f-617e94011c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoSeries([], dtype: geometry)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the boundary of chicago by joining the boundaries of the census tracts and community areas\n",
    "chic_boundary = comm_area.dissolve().unary_union.union(census.dissolve().unary_union)\n",
    "\n",
    "# find the locations that are in the census tracts or community areas of chicago\n",
    "locations_within = gpd.GeoSeries(df.pickup_location.unique()).within(chic_boundary)\n",
    "\n",
    "# Find the pickup locations that are not within the Chicago boundary\n",
    "gpd.GeoSeries(df.pickup_location.unique())[~locations_within]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0326ef-10eb-4013-8837-4039f605eda0",
   "metadata": {},
   "source": [
    "We can observe that there aren't ay rides that started outside the city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556990d3-c089-43a5-a29a-b431fd328a1a",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 24px; font-weight: bold;color: #43556A;\">\n",
    "         Drop more variables that will not be needed hereafter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa382811-21be-47db-8a63-cb53d68bc36c",
   "metadata": {},
   "source": [
    "The variables below were used/created for the data cleaning process, but they do not contain any information needed in the machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "691e8184-eafd-4334-8e1c-b25f15fb3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['pickup_comm_area', 'dropoff_comm_area', 'extras',  'trip_duration'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edf1ee8e-a580-49da-bfde-524a61cbb31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census</th>\n",
       "      <th>dropoff_census</th>\n",
       "      <th>fare</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17031081402</td>\n",
       "      <td>17031839100</td>\n",
       "      <td>9.00</td>\n",
       "      <td>POINT (-87.6129454143 41.8919715078)</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17031030604</td>\n",
       "      <td>17031832900</td>\n",
       "      <td>29.50</td>\n",
       "      <td>POINT (-87.6537935286 41.9854724225)</td>\n",
       "      <td>POINT (-87.6618611238 41.8741766252)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17031839100</td>\n",
       "      <td>17031320400</td>\n",
       "      <td>4.00</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>POINT (-87.6219716519 41.8774061234)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>17031081300</td>\n",
       "      <td>17031081500</td>\n",
       "      <td>5.75</td>\n",
       "      <td>POINT (-87.6207628651 41.8983317935)</td>\n",
       "      <td>POINT (-87.6262149064 41.8925077809)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17031081403</td>\n",
       "      <td>17031081700</td>\n",
       "      <td>6.25</td>\n",
       "      <td>POINT (-87.6188683546 41.8909220259)</td>\n",
       "      <td>POINT (-87.6318639497 41.8920421365)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    taxi_id  trip_seconds  trip_miles  pickup_census  dropoff_census   fare  \\\n",
       "16       13         600.0         0.0    17031081402     17031839100   9.00   \n",
       "18       15        1260.0         0.6    17031030604     17031832900  29.50   \n",
       "19       16         120.0         0.3    17031839100     17031320400   4.00   \n",
       "20       17         360.0         0.8    17031081300     17031081500   5.75   \n",
       "22       19         360.0         1.0    17031081403     17031081700   6.25   \n",
       "\n",
       "                         pickup_location  \\\n",
       "16  POINT (-87.6129454143 41.8919715078)   \n",
       "18  POINT (-87.6537935286 41.9854724225)   \n",
       "19  POINT (-87.6327464887 41.8809944707)   \n",
       "20  POINT (-87.6207628651 41.8983317935)   \n",
       "22  POINT (-87.6188683546 41.8909220259)   \n",
       "\n",
       "                        dropoff_location   start_day     end_day start_time  \\\n",
       "16  POINT (-87.6327464887 41.8809944707)  2019-01-01  2019-01-01   00:00:00   \n",
       "18  POINT (-87.6618611238 41.8741766252)  2019-01-01  2019-01-01   00:00:00   \n",
       "19  POINT (-87.6219716519 41.8774061234)  2019-01-01  2019-01-01   00:00:00   \n",
       "20  POINT (-87.6262149064 41.8925077809)  2019-01-01  2019-01-01   00:00:00   \n",
       "22  POINT (-87.6318639497 41.8920421365)  2019-01-01  2019-01-01   00:00:00   \n",
       "\n",
       "    end_time  \n",
       "16  00:15:00  \n",
       "18  00:30:00  \n",
       "19  00:00:00  \n",
       "20  00:15:00  \n",
       "22  00:15:00  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullstack",
   "language": "python",
   "name": "fullstack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
