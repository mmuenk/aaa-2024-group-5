{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3c7ed1-e624-43e2-a176-6d564887f7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import h3\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f3870-1650-4d36-9f04-2435594d617c",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 40px; font-weight: bold; color: #8EB944\">\n",
    "        Load the data\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b0c9bc-b7c9-41da-af11-fcd1f9ebdae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the census tract areas as a geodataframe\n",
    "census_gdf = gpd.read_file('Boundaries.geojson', crs='epsg:4326')\n",
    "\n",
    "# load the poi data as a geodataframe\n",
    "poi_gdf = gpd.read_file('POI_data.geojson', crs='epsg:4326')\n",
    "\n",
    "# load the landuse data as a geodataframe\n",
    "landuse_gdf = gpd.read_file('landuse_chicago.geojson',  crs='epsg:4326')\n",
    "\n",
    "# load the taxi trips as a dataframe (only 500k rides are needed for this notebook)\n",
    "taxi_df = pd.read_csv('clean_taxi_data.csv', nrows=500000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d7c63-7852-4a88-ac1e-b0e2dd142099",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Formatting\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080fb49-102a-42c5-99a5-7c37fe91f235",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        1. Drop rides with no dropoff location\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be61cef-4707-4f24-a475-36324e79a002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for the clustering only trips i.e. start and dropoff can be used\n",
    "taxi_df.drop(taxi_df[taxi_df.dropoff_location.isna()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a77a7-e0d3-46ed-8f9a-f099cf81cbd0",
   "metadata": {},
   "source": [
    "<span style =\"font-size: 18px; font-weight: bold;color: #43556A;\">\n",
    "        2. Recover the formatting of some variables\n",
    "</span>\n",
    "<hr style=\"color: #8EB944; height: 1px;background-color: #43556A;border: none\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57e1664-321e-4b3e-87c5-c4489813ae6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop the 'Unnamed: 0' column\n",
    "taxi_df.drop(columns=['Unnamed: 0'],inplace = True)\n",
    "\n",
    "#  convert the strings to point objects\n",
    "taxi_df['pickup_location'] = taxi_df['pickup_location'].apply(wkt.loads)\n",
    "taxi_df['dropoff_location'] = taxi_df['dropoff_location'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb342e-d28c-4197-8480-81534787e541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b33e196f-82c7-4cfb-8134-13522b9b367f",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Write helper functions\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d1700a-77de-43c6-b05b-26c315870c78",
   "metadata": {},
   "source": [
    "Write a function that gets all the unique pairs of census tract and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca721b4-9e7a-46ea-a794-b7dcc9575a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unique_census_location_pairs(taxi_df):\n",
    "    # Extract unique pair of pickup census tract and pickup location\n",
    "    unique_pickup = taxi_df[['pickup_census', 'pickup_location']].drop_duplicates()\n",
    "    \n",
    "    # Extract unique pair of dropoff census tract and dropoff location\n",
    "    unique_dropoff = taxi_df[['dropoff_census', 'dropoff_location']].drop_duplicates()\n",
    "    \n",
    "    # Rename columns to make them consistent\n",
    "    unique_pickup.columns = ['census', 'location']\n",
    "    unique_dropoff.columns = ['census', 'location']\n",
    "    \n",
    "    # Combine both dataframes and drop any duplicates\n",
    "    unique_loc = pd.concat([unique_pickup, unique_dropoff]).drop_duplicates()\n",
    "    \n",
    "    # Reset index\n",
    "    unique_loc.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return unique_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbc3e2-d594-4a24-aeaf-734018a0f0d4",
   "metadata": {},
   "source": [
    "Write a function that initializes an empty feature map that contains the hexagon id for the specified  resolution, the polygon of the hexagon and the centroid of the hexagon as well as the census tract id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436e2087-2591-4bd5-9942-34c9a2cd98f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_locations_with_h3(unique_loc, resolution=7):\n",
    "    \n",
    "    # Calculate the h3 hexagon ID for each location using the specified resolution\n",
    "    unique_loc[\"h3_hex_id\"] = unique_loc.apply(\n",
    "        lambda row: h3.geo_to_h3(row['location'].y, row['location'].x, resolution) \n",
    "        if row['location'] \n",
    "        else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Drop duplicates based on the h3 hexagon ID\n",
    "    df_unique_hex = unique_loc.drop_duplicates(subset=\"h3_hex_id\")[['census', 'h3_hex_id']]\n",
    "\n",
    "    # Calculate the geometry of the hexagons\n",
    "    df_unique_hex['geometry_hex'] = df_unique_hex.apply(\n",
    "        lambda x: Polygon(h3.h3_to_geo_boundary(x[\"h3_hex_id\"], geo_json=True)), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate the centroid of each hexagon\n",
    "    df_unique_hex['centroid'] = df_unique_hex['geometry_hex'].apply(lambda x: x.centroid)\n",
    "\n",
    "    # Create a GeoDataFrame with the centroids as geometry (change the crs of the centroids)\n",
    "    feature_map = gpd.GeoDataFrame(df_unique_hex, geometry='centroid', crs='epsg:4326').to_crs(epsg=26971).reset_index()\n",
    "\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0b05c-573b-48e2-a46c-f58934d6514c",
   "metadata": {},
   "source": [
    "Write a function that calculate the distance to the closest airport for the centroid of each hexagon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd43f85-d9b9-4865-953f-11399df71fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_min_distance_to_airport(feature_map, poi_gdf):\n",
    "    \n",
    "     # Check if the active geometry is centroid and if the CRS is 26971\n",
    "    if feature_map.geometry.name != 'centroid':\n",
    "        raise ValueError(\"The active geometry of feature_map is not 'centroid'.\")\n",
    "    if feature_map.crs.to_epsg() != 26971:\n",
    "        raise ValueError(\"The CRS of feature_map is not EPSG:26971.\")\n",
    "        \n",
    "    # Project the locations of the airports to a CRS better fitted for calculating distances in North America\n",
    "    airports = poi_gdf[poi_gdf.Category == 'Airport'].to_crs(epsg=26971)\n",
    "    \n",
    "    # Calculate the distance to the closest airport for each hexagon centroid\n",
    "    feature_map['min_dist_airport'] = feature_map.centroid.apply(\n",
    "        lambda x: airports.distance(x).round().min()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69f8a0-9311-430f-9b3a-2ffdf7e755b6",
   "metadata": {},
   "source": [
    "Write a function that calculate the distance to the city centre for the centroid of each hexagon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de007b8-877d-4aa8-9f8e-7e29709c6ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_to_city_centre(feature_map, census_gdf, commarea='32'):\n",
    "    \n",
    "    # Check if the active geometry is centroid and if the CRS is 26971\n",
    "    if feature_map.geometry.name != 'centroid':\n",
    "        raise ValueError(\"The active geometry of feature_map is not 'centroid'.\")\n",
    "    if feature_map.crs.to_epsg() != 26971:\n",
    "        raise ValueError(\"The CRS of feature_map is not EPSG:26971.\")\n",
    "    \n",
    "    # Index the community area 32 to get the census tracts that lie within that area\n",
    "    loop = census_gdf[census_gdf.commarea == commarea].to_crs(epsg=26971)\n",
    "    \n",
    "    # Calculate the distance to the city centre in meters for each hexagon centroid\n",
    "    feature_map['dist_centre'] = feature_map.centroid.apply(\n",
    "        lambda x: loop.distance(x).round().min()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959fff6-60b6-4f1f-8f3a-11efa5bd32c9",
   "metadata": {},
   "source": [
    "Write a function that checks whether there is one of the 2 airports in the hexagon. We place a buffer of 1000 metres around the location of the airports , because we did not get a polygon for the airports. A buffer of 1000 metres perfectly catches the 4 census tracts that have the 2 airports inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94d65ed-56f3-4a9e-9da2-f73ffcd2f34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def airport_in_hex(feature_map, poi_gdf):\n",
    "    # Check if the active geometry is geometry_hex and if the CRS is 4326\n",
    "    if feature_map.geometry.name != 'geometry_hex':\n",
    "        raise ValueError(\"The active geometry of feature_map is not the hexagon polygon.\")\n",
    "    if feature_map.crs.to_epsg() != 4326:\n",
    "        raise ValueError(\"The CRS of feature_map is not EPSG:4326.\")\n",
    "    \n",
    "    # Filter the POIs by the specified category\n",
    "    airports = poi_gdf[poi_gdf.Category == 'Airport']\n",
    "    \n",
    "    # Reproject the airports to a suitable CRS for distance calculations\n",
    "    airports = airports.to_crs(epsg=26971)\n",
    "    \n",
    "    # Apply a 1000-meter buffer around the POI locations (we only have the airport locations as a single point)\n",
    "    airports_buffer = airports.copy()\n",
    "    airports_buffer['geometry'] = airports_buffer.geometry.buffer(1000)\n",
    "    \n",
    "    # Reproject the feature_map to the same CRS\n",
    "    feature_map_projected = feature_map.to_crs(epsg=26971)\n",
    "    \n",
    "    # Perform a spatial join to find all hexagons that intersect with the buffered airports\n",
    "    airport_in_hex = gpd.sjoin(airports_buffer, feature_map_projected, how='inner', predicate='intersects')\n",
    "    \n",
    "\n",
    "    # Reproject feature_map back to the original CRS\n",
    "    feature_map = feature_map_projected.to_crs(epsg=4326)\n",
    "    \n",
    "    # Add the count of airports to the respective hexagon in feature_map\n",
    "    feature_map['airport_in_hex'] = feature_map.h3_hex_id.apply(\n",
    "        lambda x: 1 if x in list(airport_in_hex.h3_hex_id) else 0.0)\n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f28a3c-d057-4211-8bbf-277193b639cb",
   "metadata": {},
   "source": [
    "Write a function that counts the number of a specified poi category in the hexagon and adds it inplace to the feature map for the specific hexagon resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0381c3a9-7d26-4db7-9bab-dab5e2c759ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_poi_in_hexagons(feature_map, poi_gdf, poi_category, column_name):\n",
    "    \n",
    "    # Check if the active geometry is geometry_hex and if the CRS is 4326\n",
    "    if feature_map.geometry.name != 'geometry_hex':\n",
    "        raise ValueError(\"The active geometry of feature_map is not the hexagon polygon.\")\n",
    "    if feature_map.crs.to_epsg() != 4326:\n",
    "        raise ValueError(\"The CRS of feature_map is not EPSG:4326.\")\n",
    "    \n",
    "    # Filter the POIs by the specified category\n",
    "    pois = poi_gdf[poi_gdf.Category == poi_category]\n",
    "    \n",
    "    # Perform a spatial join to find all hexagons that contain the POIs\n",
    "    pois_in_hex = gpd.sjoin(pois, feature_map, how='inner', predicate='within')\n",
    "    \n",
    "    # Count the number of POIs in each hexagon\n",
    "    poi_counter = dict(pois_in_hex['h3_hex_id'].value_counts())\n",
    "    \n",
    "    # Add the count of POIs to the respective hexagon in feature_map\n",
    "    feature_map[column_name] = feature_map.h3_hex_id.apply(\n",
    "        lambda x: poi_counter[x] if x in poi_counter else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af222c4c-80ce-4cf5-a4be-50386d61ffdc",
   "metadata": {},
   "source": [
    "Write a function that calculates the hexagon id for the census tracts for the specified resolution, then calculates the landusage in percentage for all categories for each hexagon id. The output looks like this {'hex_id1': {'COMMERCIAL': 1.32, 'COMMUNICATION/UTILITIES': 20.84....},\n",
    " 'hex_id2': {'COMMERCIAL': 5.49,'NON-PARCEL AREAS': 66.27...}.....}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3fcdbe0-6f0c-474a-b665-e326daebd0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_landuse_hex_dict(unique_loc, landuse, resolution=7):\n",
    "\n",
    "    # change the crs of the landuse data such that it matches the other data\n",
    "    landuse.to_crs(epsg=26971, inplace=True)\n",
    "    \n",
    "    # Calculate the h3 hexagon ID for each location using the specified resolution\n",
    "    unique_loc[\"h3_hex_id\"] = unique_loc.apply(\n",
    "        lambda row: h3.geo_to_h3(row['location'].y, row['location'].x, resolution) \n",
    "        if row['location'] \n",
    "        else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Drop duplicates based on the h3 hexagon ID\n",
    "    df_unique_hex = unique_loc.drop_duplicates(subset=\"h3_hex_id\")[['census', 'h3_hex_id']]\n",
    "\n",
    "    # create a dictionary that maps the census tract id to the hexagon id\n",
    "    census_hex_dict = df_unique_hex.set_index('census')['h3_hex_id'].to_dict()\n",
    "\n",
    "    # get the hexagon id for each parcel in the landuse geodataframe\n",
    "    landuse['hex_id'] = landuse.geoid10.apply(lambda x: census_hex_dict[int(x)] \\\n",
    "                                                 if int(x) in census_hex_dict\n",
    "                                                 else None)\n",
    "    # calculate the area for each parcel\n",
    "    landuse['area'] = landuse['geometry'].area\n",
    "    \n",
    "    # Group by hexagon id and land use category to sum the areas (also reset the indexes)\n",
    "    landuse_by_category = landuse.groupby(['hex_id', 'LANDUSE'])['area'].sum().reset_index()\n",
    "\n",
    "    # Calculate the total area for each census tract\n",
    "    total_area = landuse_by_category.groupby('hex_id')['area'].sum().reset_index()\n",
    "\n",
    "    # rename the variable\n",
    "    total_area = total_area.rename(columns={'area': 'total_area'})\n",
    "\n",
    "    # Merge total_area with landuse_by_category and calculate the percentage\n",
    "    landuse_by_category = landuse_by_category.merge(total_area, on='hex_id')\n",
    "\n",
    "    # divide the area for each parcel by the area of the hexagon is is within\n",
    "    landuse_by_category['percentage'] = ((landuse_by_category['area'] / landuse_by_category['total_area'])*100).round(2)\n",
    "\n",
    "    # Create a dictionary to store results\n",
    "    landuse_dict = {}\n",
    "\n",
    "    # Populate the dictionary with the data\n",
    "    for _, row in landuse_by_category.iterrows():\n",
    "        hex_id = row['hex_id']\n",
    "        landuse = row['LANDUSE']\n",
    "        percentage = row['percentage']\n",
    "    \n",
    "        if hex_id not in landuse_dict:\n",
    "            landuse_dict[hex_id] = {}\n",
    "    \n",
    "        landuse_dict[hex_id][landuse] = percentage\n",
    "\n",
    "    return landuse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb326f73-236e-46e5-97f7-d14160254f93",
   "metadata": {},
   "source": [
    "Write a function that adds the landusage for a landuse category for each hexagon id to the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196fab98-e30e-432b-955c-6884a6bce162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_landuse_percentage(feature_map, landuse_dict, landuse_type, column_name):\n",
    "    \n",
    "    # Add the percentage of the specified land use type to the feature_map\n",
    "    feature_map[column_name] = feature_map.h3_hex_id.apply(\n",
    "        lambda x: landuse_dict[x][landuse_type] \n",
    "        if landuse_type in landuse_dict.get(x, {}) \n",
    "        else 0.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c956ea-272f-4290-aabc-fc6d6f54b3d9",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Create Feature Maps\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f4409-d520-4c18-bcbc-c3995c010c48",
   "metadata": {},
   "source": [
    "For the Support Vector Machines and the Neural Network, we will be using hexagon resolution 6 and 7. Hence, we create a feature map for each resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47eba1b6-d84e-43c0-9ce8-588d149e0849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hexagon_resolutions = [6,7]\n",
    "feature_maps = []\n",
    "\n",
    "for resolution in hexagon_resolutions:\n",
    "    #1. step: get unique locations \n",
    "    unique_loc = get_unique_census_location_pairs(taxi_df)\n",
    "\n",
    "    # 2. initialize the feature map for the hexagon resolution of 7\n",
    "    feature_map = process_locations_with_h3(unique_loc, resolution=resolution)\n",
    "\n",
    "    # 3. add distance to closest airport\n",
    "    calculate_min_distance_to_airport(feature_map, poi_gdf)\n",
    "    \n",
    "    # 4. add distance to the city centre\n",
    "    calculate_distance_to_city_centre(feature_map, census_gdf, commarea='32')\n",
    "\n",
    "    # 5. Add the occurences of a POI category\n",
    "\n",
    "    # we must change the geometry of the feature_map to the polygon for the spatial join\n",
    "    feature_map.set_geometry('geometry_hex', inplace=True)\n",
    "    feature_map.set_crs('EPSG:4326', inplace=True) \n",
    "\n",
    "    # number of stadiums in hexagon\n",
    "    count_poi_in_hexagons(feature_map, poi_gdf, 'Stadium', 'num_stadiums')\n",
    "    # number of hotels in hexagon\n",
    "    count_poi_in_hexagons(feature_map, poi_gdf, 'Hotel', 'num_hotels')\n",
    "    # number of bars/clubs in hexagon\n",
    "    count_poi_in_hexagons(feature_map, poi_gdf, 'Bar/ Night Club', 'num_bars')\n",
    "\n",
    "    # airport in hexagon\n",
    "    feature_map = airport_in_hex(feature_map, poi_gdf)\n",
    "    \n",
    "    #1. step: get unique locations \n",
    "    unique_loc = get_unique_census_location_pairs(taxi_df)\n",
    "\n",
    "    #2. step: create landuse dictionary for specified hexagon resolution\n",
    "    landuse = create_landuse_hex_dict(unique_loc, landuse_gdf, resolution=resolution)\n",
    "\n",
    "    #3. step: add the landuse percentage for each hexagon\n",
    "    add_landuse_percentage(feature_map, landuse, 'TRANSPORTATION', 'perc_transport')\n",
    "    add_landuse_percentage(feature_map, landuse, 'RESIDENTIAL', 'perc_resid')\n",
    "    add_landuse_percentage(feature_map, landuse, 'COMMERCIAL', 'perc_commerc')\n",
    "    add_landuse_percentage(feature_map, landuse, 'OPEN SPACE', 'perc_open')\n",
    "    \n",
    "    feature_maps.append(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e51491b4-df1d-4447-a1ae-0d6e2a440c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_maps[0]['centroid'] = feature_maps[0]['centroid'].astype(str)\n",
    "feature_maps[1]['centroid'] = feature_maps[1]['centroid'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242e27cf-af86-4833-8a56-a877d6742eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_maps[0].to_file('spatial_features_hex6.geojson')\n",
    "feature_maps[1].to_file('spatial_features_hex7.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2d65a-c6ba-421c-85b7-8985a16dab77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
