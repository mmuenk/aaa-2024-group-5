{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cded5ac-74c4-48ef-a1cc-1823f550ff81",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Load Libraries and Data\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf6c4ed-1f2f-4cbb-8a69-f07c84a6a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbaf1ff-66ff-4d11-ac75-1baf99a7b3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"./data/\"\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv(f'{file_path}clean_taxi_data.csv')\n",
    "\n",
    "# load the census tract areas as a geodataframe\n",
    "census_gdf = gpd.read_file(f'{file_path}Boundaries.geojson', crs='epsg:4326')\n",
    "\n",
    "# Load the weather dataset\n",
    "weather = pd.read_csv(f'{file_path}weather_chic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb48eb-5d14-4347-84a4-78369399823a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>IMPORTANT:</b> Please run this notebook three times to get all the features. Please set hexagon_resolution once to 6 and once to 7. Then run the notebook once with census_resolution set to True and hexagon_resolution set to 0.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e721ed0-3be8-4bd8-b9a3-802baf05fcb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please adjust these values\n",
    "hexagon_resolution = 0\n",
    "census_resolution = False\n",
    "\n",
    "# Depending on the case, import the corresponding spatial features, else return an error\n",
    "if hexagon_resolution == 6:\n",
    "    spatial_features = gpd.read_file('spatial_features_hex6.geojson', crs='epsg:4326')\n",
    "    \n",
    "elif hexagon_resolution == 7:\n",
    "    spatial_features = gpd.read_file('spatial_features_hex7.geojson', crs='epsg:4326')\n",
    "    \n",
    "elif census_resolution == True:\n",
    "    spatial_features = gpd.read_file('census_spatial_features.geojson', crs='epsg:4326')\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Please adjust the hexagon resolution to either 6 or 7 OR set the census_resolution to true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56444ae-aa91-4ce8-8b99-902d55436cf4",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Define important functions\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f04718-27f9-4695-894d-0b1187fbc736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_point_to_hexagon(point_wkt: str, hex_resolution: int) -> str:\n",
    "    \"\"\"\n",
    "    Convert a Well-Known Text (WKT) point string to an H3 hexagon ID.\n",
    "\n",
    "    Parameters:\n",
    "    - point_wkt (str): The Well-Known Text (WKT) representation of a point.\n",
    "    - hex_resolution (int): The resolution of the H3 hexagon (0-15).\n",
    "\n",
    "    Returns:\n",
    "    - hex_id (str): The H3 hexagon ID corresponding to the point.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the WKT point string to a Point object\n",
    "    point_obj = wkt.loads(point_wkt)\n",
    "    \n",
    "    # Convert the latitude and longitude of the Point object to an H3 hexagon ID\n",
    "    hex_id = h3.geo_to_h3(point_obj.y, point_obj.x, hex_resolution)\n",
    "    \n",
    "    return hex_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9940076-b7d7-4f4b-85c2-f46d6aaca8e4",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Feature Engineering (Weather Data)\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592d224-9993-4e98-9ccb-9092da4570bc",
   "metadata": {},
   "source": [
    "We create binary variables for rain and snow because their presence is more important than the absolute amount of precipitation. We also drop unnecessary columns that are unlikely to correlate with the number of trips to save space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb26ff87-4978-4c1c-92a9-dd12582aae7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace the values in the preciptpe column with numerical values\n",
    "weather['snow_binary'] = weather['preciptype'].apply(lambda x: 1 if x == 'snow' or x == 'rain,snow'  else 0)\n",
    "weather['rain_binary'] = weather['preciptype'].apply(lambda x: 1 if x == 'rain' or x == 'rain,snow' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df29e40-f476-4776-82fd-7c31f97189ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the Times to the datetime format\n",
    "weather['datetime'] = pd.to_datetime(weather.datetime)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "weather.drop(['name','dew','humidity','windgust','winddir','sealevelpressure','cloudcover',\n",
    "         'visibility','solarradiation','solarenergy','uvindex','conditions','icon','stations','Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4ddab-531a-48e2-9b82-d5972380d022",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Feature Engineering (Trip Data)\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69889d6c-0229-4e6a-b796-795bb3af7b4d",
   "metadata": {},
   "source": [
    "To merge the data frames, we need to round the time variable down to the nearest full hour. We also drop the columns related to the drop-off, since we are only predicting demand. Since the underlying data is in census resolution, we need to convert each point to a hex ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532bff96-2623-4ffc-9fbd-ae578a3c9a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the trip_start column to the Datetime format\n",
    "df['trip_start'] = pd.to_datetime(df.trip_start)\n",
    "\n",
    "# Round the time in the df to the nearest hour (This is needed to aggregate the data later)\n",
    "df['rounded_time'] = df['trip_start'].dt.floor('H')\n",
    "\n",
    "# Since we only predict demand, we drop all unnecessary columns\n",
    "df.drop(['Unnamed: 0','taxi_id','dropoff_location','dropoff_census'],axis=1,inplace=True)\n",
    "\n",
    "if hexagon_resolution != 0:\n",
    "    # Apply the function to your DataFrame\n",
    "    df['h3_hex_id'] = df.pickup_location.apply(lambda x: convert_point_to_hexagon(x, hexagon_resolution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145cb3b-c487-400d-b1a0-12d17bdb82f6",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Merging the Data\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9512c-7f2a-4a0d-bf34-7c02e9ba115b",
   "metadata": {},
   "source": [
    "We merge the trips dataset with the weather dataframe. We then aggregate the entire dataframe so that we have one data point for each hour and spatial bucket. We create a new column that counts the number of rows that have been aggregated, called \"rides\". This column will serve as the dependent variable later in our models. Finally, the spatial features are merged with the data frame to provide detailed spatial information about each data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6abce3-5ca0-4ea1-8f8d-6ab3783f37f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df = pd.merge(df, weather, left_on='rounded_time', right_on='datetime', how='left')\n",
    "\n",
    "# Drop the (now) unnecesarry columns\n",
    "df.drop(['datetime','trip_end','end_day','start_time','end_time','start_day','preciptype'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f82ec09-570c-403c-8928-17f5e7d3e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the column on which to aggregate the DataFrame based on which resolution we are using\n",
    "if census_resolution == True:\n",
    "    agg_column = 'pickup_census'\n",
    "else:\n",
    "    agg_column = 'h3_hex_id'\n",
    "\n",
    "# Aggregate the dataframe so that it just contains the number of rides for each hexagon and time resolution\n",
    "df_grouped = df.groupby(['rounded_time', agg_column]).agg(\n",
    "    rides=(agg_column, 'size'),  \n",
    "    trip_seconds =('trip_seconds', 'mean'),\n",
    "    trip_miles =('trip_miles', 'mean'), \n",
    "    fare=('fare', 'first'), \n",
    "    temp=('temp','first'), # All weather values are the same for the hour, so we take the first\n",
    "    precip =('precip','first'), \n",
    "    preciprob=('precipprob','first'),\n",
    "    snow=('snow','first'),\n",
    "    snowdepth=('snowdepth','first'),\n",
    "    windspeed=('windspeed','first'),\n",
    "    severerisk=('severerisk','first'),\n",
    "    snow_binary =('snow_binary','first'),\n",
    "    rain_binary = ('rain_binary','first'),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e350e073-31cd-4166-894e-2fd1b07e35c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrame with the spatial features\n",
    "if census_resolution == True:\n",
    "    \n",
    "    # Rename the pickup_census column to census\n",
    "    df_grouped.rename(columns={'pickup_census': 'census'}, inplace=True)\n",
    "    \n",
    "    # Change the datatype of the census column to int to merge it\n",
    "    spatial_features['census'] = spatial_features.census.astype('int')\n",
    "    \n",
    "    # Merge the spatial features with the DataFrame\n",
    "    df_final = pd.merge(df_grouped, spatial_features, on='census', how='left')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Merge the spatial features with the DataFrame\n",
    "    df_final = pd.merge(df_grouped, spatial_features, on='h3_hex_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8faf4a-fb92-401e-9b41-037b178583cc",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Feature Engineering\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9d95a-6bd7-45b9-a169-473964657150",
   "metadata": {},
   "source": [
    "To get additional features, especially regarding the time variables, we create several binary variables. First, the time is separated into hour, day, and month. In addition, we saw in the descriptive analysis that there are fewer trips on weekends, so we create another binary variable. Variables are created to capture morning and evening commutes during the week. We chose the times based on the demand from the descriptive analysis. Finally, we drop all columns that we consider to be weak predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f7704e8-e552-4796-870d-b99021216711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an hour, day of the week and month variable\n",
    "df_final['hour'] = df_final['rounded_time'].dt.hour\n",
    "df_final['day_of_week'] = df_final['rounded_time'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df_final['month'] = df_final['rounded_time'].dt.month\n",
    "\n",
    "# Binary variable that indicates whether the corresponding datapoint is on a weekend\n",
    "df_final['weekend_binary'] = df_final['rounded_time'].dt.dayofweek >= 5 \n",
    "\n",
    "# Binary variable that indicates whether a datapoint falls into the bar hours (on a weekend)\n",
    "df_final['bar_hours'] = df_final['hour'].apply(lambda x: 0 if x <= 18 and x >= 4 else 1)\n",
    "df_final['bar_hours_weekend'] = df_final['bar_hours'] * df_final['weekend_binary']\n",
    "\n",
    "# Binary variables that indicate either morning or evening commuting\n",
    "df_final['morning_commuting'] = df_final['hour'].apply(lambda x: 1 if x >= 5 and x<= 10 else 0)\n",
    "df_final['evening_commuting'] = df_final['hour'].apply(lambda x: 1 if x>= 13 and x<= 18 else 0)\n",
    "df_final['bar_hours_weekend'] = df_final['bar_hours'] * df_final['weekend_binary']\n",
    "df_final['morning_commuting_week'] = df_final['morning_commuting'] * (1-df_final['weekend_binary'])\n",
    "df_final['evening_commuting_week'] = df_final['evening_commuting'] * (1-df_final['weekend_binary'])\n",
    "\n",
    "if census_resolution == True:\n",
    "    df_final.drop(['trip_seconds', 'trip_miles', 'fare','preciprob', 'snow', 'snowdepth', 'windspeed',\n",
    "       'severerisk', 'snow_binary', 'rain_binary','num_stadiums','day_of_week','month','geometry'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b83e13-26e5-48b7-acff-a6d46a547031",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style =\"font-size: 30px; font-weight: bold; color: #8EB944\">\n",
    "        Exporting the final dataset\n",
    "    </span>\n",
    "    \n",
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40fde7d-7261-4122-8263-40a6ce071dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the final features DataFrame depending on the case\n",
    "if hexagon_resolution == 6:\n",
    "    df_final.to_csv('features_hex_6.csv', index=False)\n",
    "    \n",
    "elif hexagon_resolution == 7:\n",
    "    df_final.to_csv('features_hex_7.csv', index=False)\n",
    "    \n",
    "elif census_resolution == True:\n",
    "    df_final.to_csv('features_census.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Please adjust the hexagon resolution to either 6 or 7 OR set the census_resolution to true')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62468c-1ff9-4c99-9d0c-72a8762c6f2c",
   "metadata": {},
   "source": [
    "<hr style=\"color: #8EB944; height: 3px;background-color: #8EB944;border: none\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e9a2a-ffeb-42cf-ae41-b4beda3481d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf4e87-d324-4073-bc4e-de423bb735a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
