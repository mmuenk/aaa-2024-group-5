{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h3 in c:\\users\\annal\\anaconda3\\lib\\site-packages (3.7.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import h3\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#import papermill as pm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import concurrent.futures\n",
    "import random\n",
    "import os \n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "import copy\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cleaned data\n",
    "\n",
    "file_path = \"./data/\"\n",
    "\n",
    "trips_df = pd.read_csv(f\"{file_path}clean_taxi_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>taxi_id</th>\n",
       "      <th>trip_start</th>\n",
       "      <th>trip_end</th>\n",
       "      <th>trip_seconds</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>pickup_census</th>\n",
       "      <th>dropoff_census</th>\n",
       "      <th>fare</th>\n",
       "      <th>pickup_location</th>\n",
       "      <th>dropoff_location</th>\n",
       "      <th>start_day</th>\n",
       "      <th>end_day</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17031081402</td>\n",
       "      <td>17031839100</td>\n",
       "      <td>9.00</td>\n",
       "      <td>POINT (-87.6129454143 41.8919715078)</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17031030800</td>\n",
       "      <td>17031841900</td>\n",
       "      <td>29.50</td>\n",
       "      <td>POINT (-87.6641882421 41.9799124453)</td>\n",
       "      <td>POINT (-87.6429586652 41.8679024175)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17031839100</td>\n",
       "      <td>17031320400</td>\n",
       "      <td>4.00</td>\n",
       "      <td>POINT (-87.6327464887 41.8809944707)</td>\n",
       "      <td>POINT (-87.6219716519 41.8774061234)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>17031081300</td>\n",
       "      <td>17031081500</td>\n",
       "      <td>5.75</td>\n",
       "      <td>POINT (-87.6207628651 41.8983317935)</td>\n",
       "      <td>POINT (-87.6262149064 41.8925077809)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17031081403</td>\n",
       "      <td>17031081700</td>\n",
       "      <td>6.25</td>\n",
       "      <td>POINT (-87.6188683546 41.8909220259)</td>\n",
       "      <td>POINT (-87.6318639497 41.8920421365)</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  taxi_id           trip_start             trip_end  \\\n",
       "0          16       13  2019-01-01 00:00:00  2019-01-01 00:15:00   \n",
       "1          18       15  2019-01-01 00:00:00  2019-01-01 00:30:00   \n",
       "2          19       16  2019-01-01 00:00:00  2019-01-01 00:00:00   \n",
       "3          20       17  2019-01-01 00:00:00  2019-01-01 00:15:00   \n",
       "4          22       19  2019-01-01 00:00:00  2019-01-01 00:15:00   \n",
       "\n",
       "   trip_seconds  trip_miles  pickup_census  dropoff_census   fare  \\\n",
       "0         600.0         0.0    17031081402     17031839100   9.00   \n",
       "1        1260.0         0.6    17031030800     17031841900  29.50   \n",
       "2         120.0         0.3    17031839100     17031320400   4.00   \n",
       "3         360.0         0.8    17031081300     17031081500   5.75   \n",
       "4         360.0         1.0    17031081403     17031081700   6.25   \n",
       "\n",
       "                        pickup_location                      dropoff_location  \\\n",
       "0  POINT (-87.6129454143 41.8919715078)  POINT (-87.6327464887 41.8809944707)   \n",
       "1  POINT (-87.6641882421 41.9799124453)  POINT (-87.6429586652 41.8679024175)   \n",
       "2  POINT (-87.6327464887 41.8809944707)  POINT (-87.6219716519 41.8774061234)   \n",
       "3  POINT (-87.6207628651 41.8983317935)  POINT (-87.6262149064 41.8925077809)   \n",
       "4  POINT (-87.6188683546 41.8909220259)  POINT (-87.6318639497 41.8920421365)   \n",
       "\n",
       "    start_day     end_day start_time  end_time  \n",
       "0  2019-01-01  2019-01-01   00:00:00  00:15:00  \n",
       "1  2019-01-01  2019-01-01   00:00:00  00:30:00  \n",
       "2  2019-01-01  2019-01-01   00:00:00  00:00:00  \n",
       "3  2019-01-01  2019-01-01   00:00:00  00:15:00  \n",
       "4  2019-01-01  2019-01-01   00:00:00  00:15:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, train_ratio=0.75, validation_ratio=0.15):\n",
    "    features = ['pickup_census', 'trip_start', 'start_day', 'pickup_location']\n",
    "    #features_to_scale = ['demand_h-2', 'demand_h-24', 'temperature', 'precip']\n",
    "    #target = 'demand'\n",
    "    \n",
    "    # Copy the input DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Select features and target\n",
    "    X = df_copy[features]\n",
    "    y = df_copy[target]\n",
    "\n",
    "    # Split into train, validation, and test sets\n",
    "    test_ratio = (1-train_ratio)-validation_ratio\n",
    "    X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y, test_size=(1 - train_ratio), random_state=RANDOM_STATE)\n",
    "    X_val_unscaled, X_test_unscaled, y_val, y_test = train_test_split(X_test_unscaled, y_test, test_size=test_ratio / (validation_ratio + test_ratio), random_state=RANDOM_STATE)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_unscaled[features_to_scale])\n",
    "\n",
    "    X_train = X_train_unscaled.copy()\n",
    "    X_val = X_val_unscaled.copy()\n",
    "    X_test = X_test_unscaled.copy()\n",
    "\n",
    "    X_train[features_to_scale] = scaler.transform(X_train_unscaled[features_to_scale])\n",
    "    X_val[features_to_scale] = scaler.transform(X_val_unscaled[features_to_scale])\n",
    "    X_test[features_to_scale] = scaler.transform(X_test_unscaled[features_to_scale])\n",
    "\n",
    "    return (X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(param_grid, model, X, y, randomized=False):\n",
    "    if randomized:\n",
    "        grid = RandomizedSearchCV(model, param_grid)\n",
    "    else:\n",
    "        grid = GridSearchCV(model, param_grid, verbose=3)\n",
    "\n",
    "    grid.fit(X, y)\n",
    "    print(f\"Best params: {grid.best_params_}\")\n",
    "    print(f\"Scoring: {grid.best_score_}\")\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation function:\n",
    "def evaluate_model(y, y_pred):\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=128\n",
    "LEARNING_RATE=0.0025 # higher learn rate as we have a bad gpu\n",
    "OPTIMIZER=keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "LOSS='mean_squared_error'\n",
    "\n",
    "\n",
    "# Training Multiprocessing\n",
    "# It seams on a 16 core cpu we can increase this to more than 8\n",
    "MAX_WORKER_THREADS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "# as they are all the same and have no order in the dict we will just grab any element and get the shape of the train dataframe\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = datasets[random.choice(list(datasets.keys()))]\n",
    "\n",
    "model_abstract = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  # Input layer for time series data\n",
    "    layers.Dense(128, activation='relu'),     # Hidden layer 1\n",
    "    layers.Dropout(0.3),                      # Dropout layer for regularization\n",
    "    layers.Dense(64, activation='relu'),      # Hidden layer 2\n",
    "    layers.Dropout(0.2),                      # Dropout layer for regularization\n",
    "    layers.Dense(32, activation='relu'),      # Hidden layer 3\n",
    "    layers.Dropout(0.1),                      # Dropout layer for regularization\n",
    "    layers.Dense(1)                           # Output layer\n",
    "])\n",
    "model_abstract.compile(optimizer=OPTIMIZER, loss=LOSS)\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "def train_with_dataset_and_parameters(dataset_name, dataset_values):\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = dataset_values\n",
    "    \n",
    "    model = keras.models.clone_model(model_abstract)\n",
    "\n",
    "    OPTIMIZER.build(model.trainable_variables)\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    nn_metrics[dataset_name] = evaluate_model(y_test, y_preds)\n",
    "    nn_models[dataset_name] = model\n",
    "    nn_importance[dataset_name] = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "\n",
    "nn_metrics = {}\n",
    "nn_models = {}\n",
    "nn_importance = {}\n",
    "\n",
    "# Parallel execution using concurrent.futures\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKER_THREADS) as executor:\n",
    "    futures = [executor.submit(train_with_dataset_and_parameters, dataset_name, dataset_values)\n",
    "               for dataset_name, dataset_values in datasets_reduced_poly.items()]\n",
    "\n",
    "# Wait for all futures to complete\n",
    "concurrent.futures.wait(futures)\n",
    "\n",
    "for future in futures:\n",
    "    exception = future.exception()\n",
    "    if exception:\n",
    "        print(f\"Exception in future: {exception}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
